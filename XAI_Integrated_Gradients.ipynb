{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import dataset\n",
    "from tensorflow import estimator as tf_estimator\n",
    "import models.losses as losses\n",
    "import tensorflow as tf\n",
    "from models.metrics import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from seggradcam.seggradcam import SegGradCAM, ClassRoI, PixelRoI\n",
    "from seggradcam.seggradcam_block import SegGradCAM as SegGradCAM_block\n",
    "from seggradcam.seggradcam_block import ClassRoI as ClassRoI_block\n",
    "from seggradcam.seggradcam_block import PixelRoI as PixelRoI_block\n",
    "from seggradcam.visualize_sgc import SegGradCAMplot\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_threshold = 0.5\n",
    "\n",
    "hparams = {\n",
    "    # 数据路径\n",
    "    'train_path': '../dataset/next_day_wildfire_spread_train*',\n",
    "    'eval_path': '../dataset/next_day_wildfire_spread_eval*',\n",
    "    'test_path': '../dataset/next_day_wildfire_spread_test*',\n",
    "    \n",
    "    # 特征\n",
    "    'input_features': ['elevation', 'pdsi', 'NDVI', 'pr', 'sph', 'th', 'tmmn',\n",
    "                  'tmmx', 'vs', 'erc', 'population', 'PrevFireMask'],\n",
    "    'output_features': ['FireMask'],\n",
    "    \n",
    "    # 方位通道\n",
    "    'azimuth_in_channel': None,\n",
    "    'azimuth_out_channel': None,\n",
    "    \n",
    "    # 数据和模型参数\n",
    "    'data_sample_size': 64,\n",
    "    'sample_size': 32,\n",
    "    'output_sample_size': 32,\n",
    "    'batch_size': 128,\n",
    "    'shuffle': False,\n",
    "    'shuffle_buffer_size': 10000,\n",
    "    'compression_type': None,\n",
    "    'input_sequence_length': 1,\n",
    "    'output_sequence_length': 1,\n",
    "    'repeat': False,\n",
    "    'clip_and_normalize': True,\n",
    "    'clip_and_rescale': False,\n",
    "    \n",
    "    # 数据增强\n",
    "    'random_flip': False,\n",
    "    'random_rotate': False,\n",
    "    'random_crop': False,\n",
    "    'center_crop': True,\n",
    "    \n",
    "    # 其他参数\n",
    "    'downsample_threshold': 0.0,\n",
    "    'binarize_output': True\n",
    "}\n",
    "\n",
    "TITLES = [\n",
    "  'Elevation',\n",
    "  'Wind\\ndirection',\n",
    "  'Wind\\nvelocity',\n",
    "  'Min\\ntemp',\n",
    "  'Max\\ntemp',\n",
    "  'Humidity',\n",
    "  'Precip',\n",
    "  'Drought',\n",
    "  'Vegetation',\n",
    "  'Population\\ndensity',\n",
    "  'Energy\\nrelease\\ncomponent',\n",
    "  'Previous\\nfire\\nmask',\n",
    "  'Fire\\nmask',\n",
    "  'Predict\\nmask',\n",
    "]\n",
    "# Number of rows of data samples to plot\n",
    "n_rows = 30\n",
    "# Number of data variables\n",
    "n_features = 12\n",
    "# Variables for controllong the color map for the fire masks\n",
    "\n",
    "test_dataset = dataset.make_dataset(\n",
    "    hparams,\n",
    "    mode = tf_estimator.ModeKeys.PREDICT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 46\n",
    "image_list = [5, 15, 17, 21, 24, 25, 29, 33, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 125]\n",
    "inputs, labels = next(iter(test_dataset))\n",
    "image =  inputs[image_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integral_approximation(gradients):\n",
    "    # Using the trapezoidal rule to approximate the integral of the gradients\n",
    "    grads = (gradients[:-1] + gradients[1:]) / 2.0\n",
    "    integrated_gradients = np.mean(grads, axis=0)\n",
    "    return integrated_gradients\n",
    "\n",
    "\n",
    "def integrated_gradients(input_image, model, baseline=None, steps=500):\n",
    "    \"\"\"\n",
    "    计算集成梯度。\n",
    "\n",
    "    :param input_image: 输入图像，形状为 (32, 32, 12)。\n",
    "    :param model: 训练好的模型。\n",
    "    :param baseline: 基线图像，用于比较。如果为 None，则使用全零图像。\n",
    "    :param steps: 集成梯度的步数。\n",
    "    :return: 集成梯度。\n",
    "    \"\"\"\n",
    "    # 如果没有提供基线图像，则使用全零图像\n",
    "    if baseline is None:\n",
    "        baseline = np.zeros(input_image.shape)\n",
    "\n",
    "    # 线性插值\n",
    "    interpolated_images = np.array([baseline + (step / steps) * (input_image - baseline) for step in range(steps + 1)])\n",
    "    interpolated_images = tf.convert_to_tensor(interpolated_images, dtype=tf.float32)\n",
    "    # 计算预测\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(interpolated_images)\n",
    "        logits = model(interpolated_images)\n",
    "        predictions = tf.math.sigmoid(logits)\n",
    "\n",
    "    # 计算梯度\n",
    "    gradients = tape.gradient(predictions, interpolated_images)\n",
    "\n",
    "    # 计算步长的平均梯度\n",
    "    avg_gradients = integral_approximation(gradients)\n",
    "\n",
    "    # 计算集成梯度\n",
    "    integrated_gradients = (input_image - baseline) * avg_gradients\n",
    "\n",
    "    return integrated_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = tf.keras.models.load_model('saved_model/autoencoder_model', custom_objects={\n",
    "    'masked_weighted_cross_entropy_with_logits': losses.weighted_cross_entropy_with_logits_with_masked_class(pos_weight=3),\n",
    "    'AUCWithMaskedClass': AUCWithMaskedClass(with_logits=True)\n",
    "})\n",
    "unet = tf.keras.models.load_model('saved_model/unet_model', custom_objects={\n",
    "    'masked_weighted_cross_entropy_with_logits': losses.weighted_cross_entropy_with_logits_with_masked_class(pos_weight=3),\n",
    "    'AUCWithMaskedClass': AUCWithMaskedClass(with_logits=True)\n",
    "})\n",
    "resnet = tf.keras.models.load_model('saved_model/resnet_model', custom_objects={\n",
    "    'masked_weighted_cross_entropy_with_logits': losses.weighted_cross_entropy_with_logits_with_masked_class(pos_weight=3),\n",
    "    'AUCWithMaskedClass': AUCWithMaskedClass(with_logits=True)\n",
    "})\n",
    "vit = tf.keras.models.load_model('saved_model/vit_model', custom_objects={\n",
    "    'masked_weighted_cross_entropy_with_logits': losses.weighted_cross_entropy_with_logits_with_masked_class(pos_weight=3),\n",
    "    'AUCWithMaskedClass': AUCWithMaskedClass(with_logits=True)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "for i in range(len(image_list)):\n",
    "    image = inputs[image_list[i]]\n",
    "    ae_ig_attributions = integrated_gradients(image, autoencoder)\n",
    "    resnet_ig_attributions = integrated_gradients(image, resnet)\n",
    "    unet_ig_attributions = integrated_gradients(image, unet)\n",
    "\n",
    "    ae_feature_importance = np.sum(ae_ig_attributions, axis=(0, 1))\n",
    "    resnet_feature_importance = np.sum(resnet_ig_attributions, axis=(0, 1))\n",
    "    unet_feature_importance = np.sum(unet_ig_attributions, axis=(0, 1))\n",
    "\n",
    "    all_feature_importance = np.vstack([ae_feature_importance, resnet_feature_importance, unet_feature_importance])\n",
    "    df = pd.DataFrame(all_feature_importance)\n",
    "    df.insert(0, 'Model', ['AutoEncoder', 'Resnet', 'Unet'])\n",
    "    df.insert(0, 'Image_ID', [image_list[i], image_list[i], image_list[i]])\n",
    "\n",
    "    result = pd.concat([result, df], axis=0)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 12, figsize=(40,3))\n",
    "    for j in range(12):\n",
    "        ax = axes[j]\n",
    "        im = ax.imshow(np.where(ae_ig_attributions > 0, ae_ig_attributions, 0)[:, :, j], cmap='viridis')\n",
    "        fig.colorbar(im, ax=ax)\n",
    "        ax.set_title(f'Feature {j+1}')\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./ig/{image_list[i]}_ae.png')\n",
    "    # plt.show()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 12, figsize=(40,3))\n",
    "    for j in range(12):\n",
    "        ax = axes[j]\n",
    "        im = ax.imshow(np.where(resnet_ig_attributions > 0, resnet_ig_attributions, 0)[:, :, j], cmap='viridis')\n",
    "        fig.colorbar(im, ax=ax)\n",
    "        ax.set_title(f'Feature {j+1}')\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./ig/{image_list[i]}_resnet.png')\n",
    "    # plt.show()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 12, figsize=(40,3))\n",
    "    for j in range(12):\n",
    "        ax = axes[j]\n",
    "        im = ax.imshow(np.where(unet_ig_attributions > 0, unet_ig_attributions, 0)[:, :, j], cmap='viridis')\n",
    "        fig.colorbar(im, ax=ax)\n",
    "        ax.set_title(f'Feature {j+1}')\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./ig/{image_list[i]}_unet.png')\n",
    "    # plt.show()\n",
    "\n",
    "result.to_csv(\"./ig/feature_importance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ae_ig_attributions = integrated_gradients(image, autoencoder)\n",
    "# resnet_ig_attributions = integrated_gradients(image, resnet)\n",
    "# unet_ig_attributions = integrated_gradients(image, unet)\n",
    "# # vit_ig_attributions = integrated_gradients(image, vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ae_feature_importance = np.sum(ae_ig_attributions, axis=(0, 1))\n",
    "# resnet_feature_importance = np.sum(resnet_ig_attributions, axis=(0, 1))\n",
    "# unet_feature_importance = np.sum(unet_ig_attributions, axis=(0, 1))\n",
    "# # vit_feature_importance = np.sum(vit_ig_attributions, axis=(0, 1))\n",
    "\n",
    "# # 打印每个通道的重要性\n",
    "# print(ae_feature_importance)\n",
    "# print(resnet_feature_importance)\n",
    "# print(unet_feature_importance)\n",
    "# # print(vit_feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 将 NumPy 数组转换为 Pandas DataFrame\n",
    "# result = pd.DataFrame()\n",
    "# all_feature_importance = np.vstack([ae_feature_importance, resnet_feature_importance, unet_feature_importance])\n",
    "# df = pd.DataFrame(all_feature_importance)\n",
    "# df.insert(0, 'Model', ['AutoEncoder', 'Resnet', 'Unet'])\n",
    "# df.insert(0, 'Image_ID', [image_id, image_id, image_id])\n",
    "\n",
    "# result = pd.concat([result, df], axis = 0)\n",
    "# result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 12, figsize=(40,3))\n",
    "# for i in range(12):\n",
    "#     ax = axes[i]\n",
    "#     im = ax.imshow(np.where(ae_ig_attributions > 0, ae_ig_attributions, 0)[:, :, i], cmap='viridis')\n",
    "#     fig.colorbar(im, ax=ax)\n",
    "#     ax.set_title(f'Feature {i+1}')\n",
    "#     ax.axis('off')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'./ig/{image_id}_ae.png', dpi=300)\n",
    "# plt.show()\n",
    "\n",
    "# fig, axes = plt.subplots(1, 12, figsize=(40,3))\n",
    "# for i in range(12):\n",
    "#     ax = axes[i]\n",
    "#     im = ax.imshow(np.where(resnet_ig_attributions > 0, resnet_ig_attributions, 0)[:, :, i], cmap='viridis')\n",
    "#     fig.colorbar(im, ax=ax)\n",
    "#     ax.set_title(f'Feature {i+1}')\n",
    "#     ax.axis('off')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'./ig/{image_id}_resnet.png')\n",
    "# plt.show()\n",
    "\n",
    "# fig, axes = plt.subplots(1, 12, figsize=(40,3))\n",
    "# for i in range(12):\n",
    "#     ax = axes[i]\n",
    "#     im = ax.imshow(np.where(unet_ig_attributions > 0, unet_ig_attributions, 0)[:, :, i], cmap='viridis')\n",
    "#     fig.colorbar(im, ax=ax)\n",
    "#     ax.set_title(f'Feature {i+1}')\n",
    "#     ax.axis('off')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'./ig/{image_id}_unet.png')\n",
    "# plt.show()\n",
    "\n",
    "# # fig, axes = plt.subplots(1, 12, figsize=(40,3))\n",
    "# # for i in range(12):\n",
    "# #     ax = axes[i]\n",
    "# #     im = ax.imshow(np.where(vit_ig_attributions > 0, vit_ig_attributions, 0)[:, :, i], cmap='viridis')\n",
    "# #     fig.colorbar(im, ax=ax)\n",
    "# #     ax.set_title(f'Feature {i+1}')\n",
    "# #     ax.axis('off')\n",
    "# # plt.tight_layout()\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive_attributions = np.where(ig_attributions > 0, ig_attributions, 0)\n",
    "\n",
    "# # 现在对这个只包含正值的数组求和\n",
    "# feature_importance = np.sum(positive_attributions, axis=(0, 1))\n",
    "\n",
    "# # 打印每个通道的重要性\n",
    "# print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_distribution\n",
    "# positive_attributions = np.where(normalized_distribution > 0, normalized_distribution, 0)\n",
    "\n",
    "# # 现在对这个只包含正值的数组求和\n",
    "# feature_importance = np.sum(positive_attributions, axis=(0, 1))\n",
    "\n",
    "# # 打印每个通道的重要性\n",
    "# print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked_feature_importance = np.sum(masked_ig_attributions, axis=(0, 1))\n",
    "\n",
    "# # 打印每个通道的重要性\n",
    "# print(masked_feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, axes = plt.subplots(1, 12, figsize=(40,3))\n",
    "\n",
    "# # 遍历所有的特征通道\n",
    "# for i in range(12):\n",
    "#     ax = axes[i]\n",
    "#     im = ax.imshow(ig_attributions[:, :, i], cmap='viridis')\n",
    "#     # 为每个子图添加颜色条\n",
    "#     fig.colorbar(im, ax=ax)\n",
    "#     ax.set_title(f'Feature {i+1}')\n",
    "#     ax.axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 12, figsize=(40,3))\n",
    "\n",
    "# # 遍历所有的特征通道\n",
    "# for i in range(12):\n",
    "#     ax = axes[i]\n",
    "#     im = ax.imshow(positive_attributions[:, :, i], cmap='viridis')\n",
    "#     # 为每个子图添加颜色条\n",
    "#     fig.colorbar(im, ax=ax)\n",
    "#     ax.set_title(f'Feature {i+1}')\n",
    "#     ax.axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IRP-tf-210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
