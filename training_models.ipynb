{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "from tensorflow import estimator as tf_estimator\n",
    "import models.losses as losses\n",
    "import tensorflow as tf\n",
    "from models.metrics import *\n",
    "import models.cnn_autoencoder_model as cnnmodel\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    # 数据路径\n",
    "    'train_path': '../dataset/next_day_wildfire_spread_train*',\n",
    "    'eval_path': '../dataset/next_day_wildfire_spread_eval*',\n",
    "    'test_path': '../dataset/next_day_wildfire_spread_test*',\n",
    "    \n",
    "    # 特征\n",
    "    'input_features': ['elevation', 'pdsi', 'NDVI', 'pr', 'sph', 'th', 'tmmn',\n",
    "                  'tmmx', 'vs', 'erc', 'population', 'PrevFireMask'],\n",
    "    'output_features': ['FireMask'],\n",
    "    \n",
    "    # 方位通道\n",
    "    'azimuth_in_channel': None,\n",
    "    'azimuth_out_channel': None,\n",
    "    \n",
    "    # 数据和模型参数\n",
    "    'data_sample_size': 64,\n",
    "    'sample_size': 32,\n",
    "    'output_sample_size': 32,\n",
    "    'batch_size': 128,\n",
    "    'shuffle': False,\n",
    "    'shuffle_buffer_size': 10000,\n",
    "    'compression_type': None,\n",
    "    'input_sequence_length': 1,\n",
    "    'output_sequence_length': 1,\n",
    "    'repeat': False,\n",
    "    'clip_and_normalize': True,\n",
    "    'clip_and_rescale': False,\n",
    "    \n",
    "    # 数据增强\n",
    "    'random_flip': False,\n",
    "    'random_rotate': False,\n",
    "    'random_crop': False,\n",
    "    'center_crop': True,\n",
    "    \n",
    "    # 其他参数\n",
    "    'downsample_threshold': 0.0,\n",
    "    'binarize_output': True\n",
    "}\n",
    "\n",
    "train_dataset = dataset.make_dataset(\n",
    "    hparams,\n",
    "    mode = tf_estimator.ModeKeys.TRAIN\n",
    ")\n",
    "val_dataset = dataset.make_dataset(\n",
    "    hparams,\n",
    "    mode = tf_estimator.ModeKeys.EVAL\n",
    ")\n",
    "test_dataset = dataset.make_dataset(\n",
    "    hparams,\n",
    "    mode = tf_estimator.ModeKeys.PREDICT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=30,\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = tf.layers.Input((32, 32, 12))\n",
    "num_out_channels = 1\n",
    "encoder_layers = [16,32]\n",
    "decoder_layers = [32,16]\n",
    "encoder_pools = [2,2]\n",
    "decoder_pools = [2,2]\n",
    "autoencoder_model = cnnmodel.create_model(\n",
    "    input_tensor,\n",
    "    num_out_channels,\n",
    "    encoder_layers,\n",
    "    decoder_layers,\n",
    "    encoder_pools,\n",
    "    decoder_pools,\n",
    ")\n",
    "autoencoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "autoencoder_model.compile(optimizer=optimizer,\n",
    "              loss=losses.weighted_cross_entropy_with_logits_with_masked_class(pos_weight=3),\n",
    "              metrics=[AUCWithMaskedClass(with_logits=True)])\n",
    "history = autoencoder_model.fit(train_dataset, epochs=1000, validation_data=val_dataset, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Input\n",
    "import models.model_utils as model_utils\n",
    "import models.cnn_autoencoder_model as cnn_autoencoder_model\n",
    "from models.cnn_autoencoder_model import decoder\n",
    "from tensorflow.compat.v2 import keras\n",
    "\n",
    "\n",
    "layers_list = (32, 64, 128, 256, 256)\n",
    "pools_list = (2, 2, 2, 2, 2)\n",
    "decoder_layers = tuple(reversed(layers_list))\n",
    "decoder_pools = tuple(reversed(pools_list))\n",
    "num_out_channels = 1\n",
    "l1_regularization = model_utils.L1_REGULARIZATION_DEFAULT\n",
    "l2_regularization = model_utils.L2_REGULARIZATION_DEFAULT\n",
    "\n",
    "# define input\n",
    "conv_input = Input(shape=(32,32,12))\n",
    "\n",
    "# add extra convolutional layer\n",
    "conv_output = tf.keras.layers.Conv2D(16, (3, 3), padding='same')(conv_input)\n",
    "\n",
    "# define resnet encoder\n",
    "keras_resnet_encoder = ResNet50(weights=None,\n",
    "                 include_top=False,\n",
    "                input_shape=(32, 32, 16))\n",
    "\n",
    "encoder_output = keras_resnet_encoder(conv_output)\n",
    "\n",
    "# define resnet decoder\n",
    "# decoder_input_img = Input(shape=keras_resnet_encoder.output_shape[1:])\n",
    "\n",
    "x = decoder(encoder_output, decoder_layers, decoder_pools)\n",
    "decoder_output = model_utils.conv2d_layer(\n",
    "      filters=num_out_channels,\n",
    "      kernel_size=model_utils.RES_SHORTCUT_KERNEL_SIZE,\n",
    "      l1_regularization=l1_regularization,\n",
    "      l2_regularization=l2_regularization)(x)\n",
    "\n",
    "# keras_resnet_decoder = keras.Model(decoder_input_img, resnet_decoder)\n",
    "\n",
    "# decoder_output = keras_resnet_decoder(encoder_output)\n",
    "\n",
    "# define connected model\n",
    "keras_model = keras.Model(inputs = conv_input, outputs = decoder_output)\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "keras_model.compile(optimizer=optimizer,\n",
    "              loss=losses.weighted_cross_entropy_with_logits_with_masked_class(pos_weight=3),\n",
    "              metrics=[AUCWithMaskedClass(with_logits=True)])\n",
    "history = keras_model.fit(train_dataset, epochs=1000, validation_data=val_dataset, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expend_as(tensor, rep):\n",
    "     return Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),\n",
    "                          arguments={'repnum': rep})(tensor)\n",
    "\n",
    "def double_conv_layer(x, filter_size, size, dropout, batch_norm=False):\n",
    "    axis = 3\n",
    "    conv = SeparableConv2D(size, (filter_size, filter_size), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = SeparableConv2D(size, (filter_size, filter_size), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    if dropout > 0:\n",
    "        conv = Dropout(dropout)(conv)\n",
    "\n",
    "    shortcut = Conv2D(size, kernel_size=(1, 1), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        shortcut = BatchNormalization(axis=axis)(shortcut)\n",
    "\n",
    "    res_path = add([shortcut, conv])\n",
    "    return res_path\n",
    "\n",
    "def encoder(inputs):\n",
    "    num_filters = [16, 32, 64, 128]\n",
    "    skip_connections = []\n",
    "    x = inputs\n",
    "\n",
    "    for i, f in enumerate(num_filters):\n",
    "        a = double_conv_layer(x, 3, f, 0.1, True)\n",
    "        skip_connections.append(a)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(a)\n",
    "    \n",
    "    return x, skip_connections\n",
    "\n",
    "def bottleneck(inputs):\n",
    "    x = inputs\n",
    "    f = 256\n",
    "    \n",
    "    x3 = double_conv_layer(x, 3, f, 0.1, True)\n",
    "    \n",
    "    return x3\n",
    "\n",
    "def decoder(inputs, skip_connections):\n",
    "    num_filters = [128, 64, 32, 16]\n",
    "    skip_connections.reverse()\n",
    "    x = inputs\n",
    "    batch_norm = True\n",
    "    \n",
    "    for i, f in enumerate(num_filters):\n",
    "        \n",
    "        x_up = UpSampling2D(size=(2, 2), data_format=\"channels_last\")(x)\n",
    "        x_att = concatenate([x_up, skip_connections[i]], axis=-1)\n",
    "        \n",
    "        x = double_conv_layer(x_att, 3, f, 0.1, True)\n",
    "    return x\n",
    "\n",
    "def output(inputs):\n",
    "    x = Conv2D(1, kernel_size=(1,1))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    # x = Activation('sigmoid')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "inputs = Input((32, 32, 12))\n",
    "# s = layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs)\n",
    "s = inputs\n",
    "x, skip_1 = encoder(s)\n",
    "x = bottleneck(x)\n",
    "x = decoder(x, skip_1)\n",
    "outputs = output(x)\n",
    "unet_model = Model(inputs, outputs)\n",
    "unet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "unet_model.compile(optimizer=optimizer,\n",
    "              loss=losses.weighted_cross_entropy_with_logits_with_masked_class(pos_weight=2),\n",
    "              metrics=[AUCWithMaskedClass(with_logits=True)])\n",
    "history = unet_model.fit(train_dataset, epochs=1000, validation_data=val_dataset, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, concatenate\n",
    "\n",
    "import keras_vision_transformer as create_swin_unet\n",
    "from keras_vision_transformer.create_swin_unet import swin_unet_2d_base\n",
    "\n",
    "import keras_vision_transformer.create_swin_unet_add_convolution\n",
    "from keras_vision_transformer.create_swin_unet_add_convolution import swin_unet_2d_base\n",
    "\n",
    "filter_num_begin = 128     # number of channels in the first downsampling block; it is also the number of embedded dimensions\n",
    "depth = 4                  # the depth of SwinUNET; depth=4 means three down/upsampling levels and a bottom level\n",
    "stack_num_down = 2         # number of Swin Transformers per downsampling level\n",
    "stack_num_up = 2           # number of Swin Transformers per upsampling level\n",
    "patch_size = (2, 2)        # Extract 4-by-4 patches from the input image. Height and width of the patch must be equal.\n",
    "num_heads = [4, 8, 8, 8]   # number of attention heads per down/upsampling level\n",
    "window_size = [4, 2, 2, 2] # the size of attention window per down/upsampling level\n",
    "num_mlp = 512              # number of MLP nodes within the Transformer\n",
    "shift_window=True          # Apply window shifting, i.e., Swin-MSA\n",
    "\n",
    "# define input size\n",
    "input_size = (32,32,12)\n",
    "IN = Input(input_size)\n",
    "\n",
    "# Base architecture\n",
    "X = swin_unet_2d_base(IN, filter_num_begin, depth, stack_num_down, stack_num_up,\n",
    "                      patch_size, num_heads, window_size, num_mlp,\n",
    "                      shift_window=shift_window, name='swin_unet')\n",
    "\n",
    "# define output: remove activation function\n",
    "n_labels = 1\n",
    "OUT = Conv2D(n_labels, kernel_size=1, use_bias=False, padding='same')(X)\n",
    "\n",
    "# Model Configuration\n",
    "keras_model = Model(inputs=IN, outputs=OUT)\n",
    "\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "keras_model.compile(optimizer=optimizer,\n",
    "              loss=losses.weighted_cross_entropy_with_logits_with_masked_class(pos_weight=4),\n",
    "              metrics=[AUCWithMaskedClass(with_logits=True)])\n",
    "history = keras_model.fit(train_dataset, epochs=1000, validation_data=val_dataset, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
